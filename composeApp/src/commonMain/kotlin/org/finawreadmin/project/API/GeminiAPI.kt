package org.finawreadmin.project.API

import com.google.generativeai.GenerativeModel
import com.google.generativeai.type.History
import com.google.generativeai.type.SystemInstruction

// Import your BuildConfig generated by Gradle
import org.finawreadmin.project.BuildConfig // Adjust this import based on your actual package name

// You might not need Ktor directly for Gemini API calls if you use the official SDK.
// However, if you have other HTTP needs, keep it.
import io.ktor.client.*
import io.ktor.client.engine.cio.*
import io.ktor.client.plugins.contentnegotiation.*
import io.ktor.client.request.*
import io.ktor.client.statement.*
import io.ktor.http.*
import io.ktor.serialization.kotlinx.json.*
import kotlinx.serialization.json.*

suspend fun callGemini(prompt: String): String? {
    // Get the API key from BuildConfig
    val geminiApiKey = BuildConfig.GEMINI_API_KEY

    // Initialize the GenerativeModel with your API key and the desired model
    val generativeModel = GenerativeModel(
        modelName = "gemini-1.5-flash",
        apiKey = geminiApiKey // Use the API key from BuildConfig
    )

    // Gemini uses a "system instruction" for model persona, similar to OpenAI's system role.
    val systemInstruction = SystemInstruction.from("You are an expert educational content generator.")

    val chat = generativeModel.startChat(
        history = History(), // Start with an empty chat history if this is a new conversation
        systemInstruction = systemInstruction
    )

    try {
        val response = chat.sendMessage(prompt) // Send the user's prompt

        // Access the generated content
        return response.text
    } catch (e: Exception) {
        // Handle API errors
        e.printStackTrace()
        return null
    }
}

